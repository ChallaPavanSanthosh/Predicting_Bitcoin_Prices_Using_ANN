{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41e520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c9206d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\HP\\\\Desktop\\\\apex\\\\project\\\\Predicting_Bitcoin_Prices_Using_ANN\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a1f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f3a1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\HP\\\\Desktop\\\\apex\\\\project\\\\Predicting_Bitcoin_Prices_Using_ANN'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71fc5db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c957760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ANNClassifier.constants import *\n",
    "# from ANNClassifier.utils.common import read_yaml\n",
    "\n",
    "from src.ANNClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a49b4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "            config = self.config.data_ingestion\n",
    "\n",
    "            create_directories([config.root_dir])\n",
    "\n",
    "            data_ingestion_config = DataIngestionConfig(\n",
    "                root_dir= config.root_dir,\n",
    "                source_URL= config.source_URL,\n",
    "                local_data_file= config.local_data_file,\n",
    "                unzip_dir=config.unzip_dir\n",
    "            )\n",
    "\n",
    "            return data_ingestion_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81724e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "from ANNClassifier import logger\n",
    "from ANNClassifier.utils.common import get_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c46483ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def download_file(self) -> str:\n",
    "        '''\n",
    "        Fetch data from the url\n",
    "        '''\n",
    "\n",
    "        try:\n",
    "            dataset_url = self.config.source_URL\n",
    "            zip_download_dir = self.config.local_data_file\n",
    "            os.makedirs(\"artifacts/data_ingestion\", exist_ok=True)\n",
    "            logger.info(f\"Downloading data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "            file_id = dataset_url.split(\"/\")[-2]\n",
    "            prefix = 'https://drive.google.com/uc?export=download&id='\n",
    "            gdown.download(prefix+file_id, zip_download_dir)\n",
    "\n",
    "            logger.info(f\"Downloaded data from {dataset_url} into file {zip_download_dir}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8973654e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-23 13:34:56,300: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-07-23 13:34:56,303: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-07-23 13:34:56,305: INFO: common: created directory at: artifacts]\n",
      "[2025-07-23 13:34:56,307: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2025-07-23 13:34:56,308: INFO: 1235392990: Downloading data from https://drive.google.com/file/d/1zbilaliA_PAH7xMBGsrgYEuwb-PzvS6T/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?export=download&id=1zbilaliA_PAH7xMBGsrgYEuwb-PzvS6T\n",
      "From (redirected): https://drive.google.com/uc?export=download&id=1zbilaliA_PAH7xMBGsrgYEuwb-PzvS6T&confirm=t&uuid=5b8f77a3-8a6e-485b-b608-ab7c45576ebb\n",
      "To: c:\\Users\\HP\\Desktop\\apex\\project\\Predicting_Bitcoin_Prices_Using_ANN\\artifacts\\data_ingestion\\data.zip\n",
      "100%|██████████| 369M/369M [00:36<00:00, 10.2MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-23 13:35:39,783: INFO: 1235392990: Downloaded data from https://drive.google.com/file/d/1zbilaliA_PAH7xMBGsrgYEuwb-PzvS6T/view?usp=sharing into file artifacts/data_ingestion/data.zip]\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     data_ingestion\u001b[38;5;241m.\u001b[39mextract_zip_file()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     data_ingestion \u001b[38;5;241m=\u001b[39m DataIngestion(config\u001b[38;5;241m=\u001b[39mdata_ingestion_config)\n\u001b[0;32m      5\u001b[0m     data_ingestion\u001b[38;5;241m.\u001b[39mdownload_file()\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mdata_ingestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_zip_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[25], line 34\u001b[0m, in \u001b[0;36mDataIngestion.extract_zip_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m unzip_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39munzip_dir\n\u001b[0;32m     33\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(unzip_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_data_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[0;32m     35\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(unzip_path)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\bitcoin\\lib\\zipfile.py:1257\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1257\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1258\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1259\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\bitcoin\\lib\\zipfile.py:1324\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4404a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d36f4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from logging import getLogger\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c179c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01393145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "        create_directories([config.root_dir])\n",
    "        return DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_URL=config.source_URL,\n",
    "            local_data_file=config.local_data_file\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d673639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_file(self) -> None:\n",
    "        try:\n",
    "            dataset_url = self.config.source_URL\n",
    "            download_path = self.config.local_data_file\n",
    "            os.makedirs(self.config.root_dir, exist_ok=True)\n",
    "\n",
    "            logger.info(f\"Downloading CSV from {dataset_url} into {download_path}\")\n",
    "            gdown.download(dataset_url, str(download_path), quiet=False, fuzzy=True)\n",
    "            logger.info(f\"Download completed: {download_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(\"Download failed\")\n",
    "            raise e\n",
    "\n",
    "    def load_csv(self) -> pd.DataFrame:\n",
    "        try:\n",
    "            logger.info(f\"Loading CSV file from {self.config.local_data_file}\")\n",
    "            df = pd.read_csv(self.config.local_data_file)\n",
    "            logger.info(f\"CSV file loaded with shape: {df.shape}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(\"Failed to load CSV\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52422d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-30 19:12:02,923: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-07-30 19:12:02,947: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-07-30 19:12:02,950: INFO: common: created directory at: artifacts]\n",
      "[2025-07-30 19:12:02,953: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2025-07-30 19:12:02,955: INFO: 2364431818: Downloading CSV from https://drive.google.com/file/d/1zbilaliA_PAH7xMBGsrgYEuwb-PzvS6T/view?usp=sharing into artifacts/data_ingestion/data.csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1zbilaliA_PAH7xMBGsrgYEuwb-PzvS6T\n",
      "From (redirected): https://drive.google.com/uc?id=1zbilaliA_PAH7xMBGsrgYEuwb-PzvS6T&confirm=t&uuid=93c0fabd-0197-49f9-8fa6-425db9194a1c\n",
      "To: c:\\Users\\HP\\Desktop\\apex\\project\\Predicting_Bitcoin_Prices_Using_ANN\\artifacts\\data_ingestion\\data.csv\n",
      "100%|██████████| 369M/369M [02:19<00:00, 2.65MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-30 19:14:30,283: INFO: 2364431818: Download completed: artifacts/data_ingestion/data.csv]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataIngestion' object has no attribute 'extract_zip_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     data_ingestion\u001b[38;5;241m.\u001b[39mextract_zip_file()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     data_ingestion \u001b[38;5;241m=\u001b[39m DataIngestion(config\u001b[38;5;241m=\u001b[39mdata_ingestion_config)\n\u001b[0;32m      5\u001b[0m     data_ingestion\u001b[38;5;241m.\u001b[39mdownload_file()\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mdata_ingestion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_zip_file\u001b[49m()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataIngestion' object has no attribute 'extract_zip_file'"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6aedf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-23 18:20:14,278: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-07-23 18:20:14,280: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-07-23 18:20:14,282: INFO: common: created directory at: artifacts]\n",
      "[2025-07-23 18:20:14,283: INFO: common: created directory at: artifacts/data_ingestion]\n",
      "[2025-07-23 18:20:14,285: INFO: 2364431818: Downloading CSV from https://drive.google.com/file/d/1zbilaliA_PAH7xMBGsrgYEuwb-PzvS6T/view?usp=sharing into artifacts/data_ingestion/data.csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1zbilaliA_PAH7xMBGsrgYEuwb-PzvS6T\n",
      "From (redirected): https://drive.google.com/uc?id=1zbilaliA_PAH7xMBGsrgYEuwb-PzvS6T&confirm=t&uuid=6646bd87-dbc7-42be-890d-9bcb00af01f9\n",
      "To: c:\\Users\\HP\\Desktop\\apex\\project\\Predicting_Bitcoin_Prices_Using_ANN\\artifacts\\data_ingestion\\data.csv\n",
      "100%|██████████| 369M/369M [00:32<00:00, 11.4MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-23 18:20:49,264: INFO: 2364431818: Download completed: artifacts/data_ingestion/data.csv]\n",
      "[2025-07-23 18:20:49,265: INFO: 2364431818: Loading CSV file from artifacts/data_ingestion/data.csv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-23 18:20:52,269: INFO: 2364431818: CSV file loaded with shape: (7073005, 6)]\n",
      "      Timestamp  Open  High   Low  Close  Volume\n",
      "0  1.325412e+09  4.58  4.58  4.58   4.58     0.0\n",
      "1  1.325412e+09  4.58  4.58  4.58   4.58     0.0\n",
      "2  1.325412e+09  4.58  4.58  4.58   4.58     0.0\n",
      "3  1.325412e+09  4.58  4.58  4.58   4.58     0.0\n",
      "4  1.325412e+09  4.58  4.58  4.58   4.58     0.0\n",
      "✅ CSV loaded successfully. Shape: (7073005, 6)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Step 1: Load config\n",
    "    config = ConfigurationManager()\n",
    "\n",
    "    # Step 2: Get data ingestion configuration\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "\n",
    "    # Step 3: Initialize ingestion\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "\n",
    "    # Step 4: Download the CSV file\n",
    "    data_ingestion.download_file()\n",
    "\n",
    "    # Step 5: Load the CSV into a DataFrame\n",
    "    df = data_ingestion.load_csv()\n",
    "\n",
    "    # Optional: Preview or log DataFrame shape\n",
    "    print(df.head())  # or logger.info(df.head())\n",
    "    print(f\"✅ CSV loaded successfully. Shape: {df.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during data ingestion: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8c8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitcoin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
